{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "091d9ba9-c402-4b7c-ab9c-f05e962c9086",
   "metadata": {},
   "source": [
    "# Working with files in Python\n",
    "\n",
    "Many of the files that bioinformaticians work with are flat text files. That means that reading and writing most of the files you will be dealing with can be acheived using the same tools. To read in special filetypes like Microsoft Office files or images, you will need to use additional packages which offer that functionality. For the purposes of this course, we will be sticking with reading and writing text files.\n",
    "\n",
    "## Opening files with `open()`\n",
    "\n",
    "Python comes with a built-in function to open files stored on your computer: `open()`. `open()` returns a class that has several methods for interacting with files. Here, we're going to go over the `.read()`, `.readlines()`, `.write()`, and `.close()` methods. Before we can use one of those methods, though, we first need to open a file. I have included an example file, \"plantgrowth.txt\", along with these notebook files for you to work with.\n",
    "\n",
    "You can open a file using `open()`, but specifying the filepath and the opening mode. Opening mode refers to whether you are going to read (\"r\"), write (\"w\"), or append (\"a\") to the file. The default mode is read. There are also some other modes that we won't cover here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68e23c10-a5d9-4196-8eb6-d9ef130b3a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='plantgrowth.txt' mode='r' encoding='UTF-8'>\n"
     ]
    }
   ],
   "source": [
    "# If you don't specify mode, then the file is opened with read mode. Equivalent to read(<filepath>, 'r')\n",
    "file = open(\"plantgrowth.txt\")\n",
    "print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1716f7-6dff-4173-84e0-17a0e692ae84",
   "metadata": {},
   "source": [
    "## `.read()`\n",
    "\n",
    "Now that we have opened our file, we can interact with it using the variable `file` to get access to the contents of the file. The simplest way to get the contents of a file is using the `.read()` method. `.read()` returns the entire file contents as a `str`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cc40032-393a-4e66-84bf-f0dc28822465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight\tgroup\n",
      "4.17\tctrl\n",
      "5.58\tctrl\n",
      "5.18\tctrl\n",
      "6.11\tct\n"
     ]
    }
   ],
   "source": [
    "contents = file.read()\n",
    "print(contents[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ac0666-73d3-4387-b1d4-b725a3d68af6",
   "metadata": {},
   "source": [
    "Note that we can only read a file once. After that we need to open it again if we want to do something with it. However, we still need to remember to close it using `.close()`. If we don't close files the we clutter up our memory with the open files. If you are opening many or large files you might run into an error complaining you have too many files open."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fc595c4-b6ea-45a9-ad9d-d9cb943b7226",
   "metadata": {},
   "outputs": [],
   "source": [
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d86183-0281-4ece-8c31-68eb5479e6ab",
   "metadata": {},
   "source": [
    "Even though our file is now closed, we still have access to the contents that we read into our `contents` variable. We can now work with the data within.\n",
    "\n",
    "The data in this file are the weights of plants treated with either a control condition or one of two treatments. Each line represents a different plant and includes its weight and treatment condition. Above, we printed the first 50 characters of the file contents to see what it looked like. We can see indication that there are newlines as the data are not all on one line. We can also see evidence of tabs as each column is aligned. However that might be spaces. We can view whitespace characters as literals (e.g., \"\\n\", \"\\t\" etc) using the Python built=in function `repr()`. `repr()` returns a string representation of an object in such a way that you could copy and paste the output into a Python script to recreate the printed object ([See the docs here](https://docs.python.org/3/library/functions.html#repr))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebcf59de-03d9-4261-8bc5-f318a024bbc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'weight\\tgroup\\n4.17\\tctrl\\n5.58\\tctrl\\n5.18\\tctrl\\n6.11\\tct'\n"
     ]
    }
   ],
   "source": [
    "print(repr(contents[:50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18ac2a2-eb07-4bf5-9716-fa4ff4845ed9",
   "metadata": {},
   "source": [
    "If we want to extract the data in each column of each line, then we need to handle the delimiters separating those data. There are two delimiters in this file: newlines (\"\\n\") and tabs (\"\\t\"). Newlines separate each sample, while tabs separate the data associated with each sample. Fortunately, the contents of the file are stored in a `str` instance and `str` has a method specifically for dealing with situations like this: `.split()`. \n",
    "\n",
    "We covered `.split()` in an earlier notebook. `.split()` takes a delimiter as input and splits a `str` into a `list` using that delimter. The deafault delimiter used by `.split()` is any whitespace character. That default would certainly split up our data, but we would lose the structure provided by the two delimiters. Therefore, we should instead split twice. First on newlines, then on tabs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c55692-4a39-408c-8cd9-33e99143e3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['weight\\tgroup', '4.17\\tctrl', '5.58\\tctrl']\n"
     ]
    }
   ],
   "source": [
    "file_lines = contents.split(\"\\n\")\n",
    "print(file_lines[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8271fd9-2c04-4a3d-9a13-6d30f8ee208e",
   "metadata": {},
   "source": [
    "Now we have a list of our lines. We have separated our samples from one another, but have retained the association of the weight and treatment for each sample.\n",
    "\n",
    "Next we need to decide how to store our data in a useful way for further processing. We have a few options. We could further unpack our data by splitting each element of the `file_lines` list so that we have a list of lists. However, if we ever want to retrieve all of the treatment 1 samples, we would then have to iterate over ever sample and use an `if` statement to identify the ones with the desired treatment. Instead, let's use a `dict`. Whenever you are in a situation where you might want to look up data using some other associated date (in this case the treatment), a `dict` should be your first thought.\n",
    "\n",
    "I think a sensible `dict` structure to use is one in which treatment types are the keys and the list of weights of samples given each treatment are the values. We could represent that with pseudocode as `{<treatment>: <list of weights>}`. It can be helpful to add pseudocode like that as a comment when you create a `dict` so that you have a reference later of what the structure of the `dict` is.\n",
    "\n",
    "For now, we're going to use a cumbersome approach to build this `dict`. However, once we cover importing modules, we'll start using an easier approach to make `dict`s like this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aab6787-a5b7-48d5-9b5f-8fff4500a033",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m treatment_weights_dict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m file_lines[\u001b[38;5;241m1\u001b[39m:]: \u001b[38;5;66;03m# [1:] skips the first one as we don't need to store the headers\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     weight, treatment \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m treatment \u001b[38;5;129;01min\u001b[39;00m treatment_weights_dict: \u001b[38;5;66;03m# does the key already exist\u001b[39;00m\n\u001b[1;32m      5\u001b[0m         treatment_weights_dict[treatment]\u001b[38;5;241m.\u001b[39mappend(weight) \u001b[38;5;66;03m# lookup the list associated with treatment and append this weight to that list\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "treatment_weights_dict = {}\n",
    "for line in file_lines[1:]: # [1:] skips the first one as we don't need to store the headers\n",
    "    weight, treatment = line.split(\"\\t\")\n",
    "    if treatment in treatment_weights_dict: # does the key already exist\n",
    "        treatment_weights_dict[treatment].append(weight) # lookup the list associated with treatment and append this weight to that list\n",
    "    else: # if not, add it with a list as the value\n",
    "        treatment_weights_dict[treatment] = [weight]\n",
    "\n",
    "# Now we have a nicely organized object storing our data\n",
    "print(treatment_weights_dict[\"ctrl\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746af0d0-1e1e-4c9a-b61e-2ef208cd266f",
   "metadata": {},
   "source": [
    "**What went wrong???**\n",
    "\n",
    "The above error is a little confusing. We saw above that we can split our file on newlines and get a list of tab-delimited columns like `['weight\\tgroup', '4.17\\tctrl', '5.58\\tctrl']`. So why is there only one element when we then split those on tabs?\n",
    "\n",
    "If we try to run the above code on just the first three lines that we've looked at, it works fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbd39ef1-72ad-47ab-9c2e-d331cb9c0e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight group\n",
      "4.17 ctrl\n",
      "5.58 ctrl\n"
     ]
    }
   ],
   "source": [
    "for line in file_lines[:3]:\n",
    "    weight, treatment = line.split(\"\\t\")\n",
    "    print(weight, treatment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cec3340-1093-44f5-87d2-527ae462a6fe",
   "metadata": {},
   "source": [
    "So the columns of each line are unpacking into our two variables just fine. So what is the problem?\n",
    "\n",
    "The issue here is a quirk of how `.split()` behaves. `.split()` searches a `str` for every instance of the delimiter character and, everytime it finds a delimiter, it stores the string to the left and to the right of that delimiter. The above error is occuring because EVERY line in a file ends in a newline. That means that there is a newline (i.e., our delimiter) at the very end of the file as well. What `.split()` does in that case is it includes the string to the right of that final newline in the returned `list`. I.e., there is an empty string at the end of our list.\n",
    "\n",
    "We can see that if we look at the end of our `file_lines` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "129ed966-2afb-48d6-951b-48cbbddab714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5.26\\ttrt2', '']\n"
     ]
    }
   ],
   "source": [
    "print(file_lines[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a34edf-b4ec-44e6-b1c3-39e54046ead2",
   "metadata": {},
   "source": [
    "**What can we do about it?**\n",
    "\n",
    "We have two options to handle the blank lines. We can remove them from the `list` we are iterating over using something like the `filter()` function ([docs here](https://docs.python.org/3/library/functions.html#filter), or we can add code to our loop to handle blank lines. Let's use `filter()` for now. We will cover how to better control our loops in a later class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71fa0e88-f9a8-453d-98d4-1bd64a52bec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4.17', '5.58', '5.18', '6.11', '4.5', '4.61', '5.17', '4.53', '5.33', '5.14']\n"
     ]
    }
   ],
   "source": [
    "treatment_weights_dict = {}\n",
    "for line in filter(None, file_lines[1:]): # filter(None, <iterable>) ignores any blank elements in the iterable\n",
    "    weight, treatment = line.split(\"\\t\")\n",
    "    if treatment in treatment_weights_dict: # does the key already exist\n",
    "        treatment_weights_dict[treatment].append(weight) # lookup the list associated with treatment and append this weight to that list\n",
    "    else: # if not, add it with a list as the value\n",
    "        treatment_weights_dict[treatment] = [weight]\n",
    "\n",
    "# Now we have a nicely organized object storing our data\n",
    "print(treatment_weights_dict[\"ctrl\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27a8b8e-6499-4e15-8c17-4dec526cf95c",
   "metadata": {},
   "source": [
    "Now it is working and we have a nicely organized object that we can use to analyze the data in our file.\n",
    "\n",
    "That was quite a lot of work, though. Most of the files we work with have lines in them, and it is common to want to process a file line by line. It would be a pain to always have to read in the whole file, split on newlines, and have to remember to remove blank lines. Fortunately, there is a method that handles that for us: `.readlines()`.\n",
    "\n",
    "## `.readlines()`\n",
    "\n",
    "`.readlines()` handles a lot of what we just did above for us. Specifically, it returns an [iterator](https://docs.python.org/3/glossary.html#term-iterator) object (i.e., an object that gives us it's elements one by one for use in a loop) that returns each line of the file one by one. It doesn't return a blank line at the end (though it will still return blank lines in the middle of the file if there are any). However, as we aren't splitting the `str`, the newline delimiter is not removed. We can easily get rid of trailing newlines with `.strip()`\n",
    "\n",
    "As we have already read our file, we need to open it again to use `.readlines()`. However, as we are able to use `.readlines()` to iterate over the lines of our file, we don't need to immediately split our file into a `list`. Instead, we can go straight into our loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a74804d9-829d-4a0a-a499-e6550579b32d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4.17', '5.58', '5.18', '6.11', '4.5', '4.61', '5.17', '4.53', '5.33', '5.14']\n"
     ]
    }
   ],
   "source": [
    "file = open(\"plantgrowth.txt\")\n",
    "treatment_weights_dict = {}\n",
    "for line in file.readlines()[1:]: # .readlines() is a method of our open file object. [1:] to skip the header line\n",
    "    weight, treatment = line.strip().split(\"\\t\") # strip away trailing newlines, then split the str\n",
    "    if treatment in treatment_weights_dict: # does the key already exist\n",
    "        treatment_weights_dict[treatment].append(weight) # lookup the list associated with treatment and append this weight to that list\n",
    "    else: # if not, add it with a list as the value\n",
    "        treatment_weights_dict[treatment] = [weight]\n",
    "\n",
    "# close the file once we are done reading it\n",
    "file.close()\n",
    "# Now we have a nicely organized object storing our data\n",
    "print(treatment_weights_dict[\"ctrl\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c21aa95-93aa-48ca-b64a-ee2fc3332703",
   "metadata": {
    "tags": []
   },
   "source": [
    "That was much easier than reading the whole file and handline splitting ourselves. The only extra thing to remember is that we need to strip the trailing newline from each line as `.readlines()` does not remove the newlines for us.\n",
    "\n",
    "## Splitting and chaining methods\n",
    "\n",
    "There's actually a simple way to not have to do that `.strip()` operation, but I did it that way to introduce a new idea: chaining methods together like `line.strip().split(\"\\t\")`. Before we get into that, let's quickly go over the way we could have done the above without `.strip()`.\n",
    "\n",
    "### `.split()` behaviors\n",
    "\n",
    "Perhaps the most common usecase of `.split()` is to break up lines of text into columns. Depending on the formatting of the text, you will use `.split()` in different ways. The default mode for `.split()` uses any number of whitespace characters as a delimiter. This is useful when your file is column-based, but the columns are padded with space characters to align the columns. Depending on the length of column contents, it takes a different number of spaces to align the following column. See for example the following string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49151694-8b6a-403c-916a-f36aba7dfcbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['column1', 'column2', 'column3']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"column1 column2                    column3\\n\".split()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c16df41-6b08-4031-89c1-3af974564312",
   "metadata": {},
   "source": [
    "Even though there was an inconconsistent number of spaces between the three columns, `.split()` was able to correctly identify which column was which. It also didn't return an empty string at the end of the list. The reason for this is the algorithm used by `.split()` when operating in its default mode.\n",
    "\n",
    "If you think about how you could go about writing a program that would identify elements separated by an unknown number of whitespace characters, one solution you might come up with is to split on every individual whitespace character and then remove any empty strings. All that would remain then is the non-empty elements you were looking for. That is how `.split()` works when no delimiter is specified. Therefore, no empty strings are present at the end of the returned list.\n",
    "\n",
    "The alternative mode for `.split()` is when a delimiter is specified. This mode is useful when you are reading a csv or other format where there is a fixed delimiter. When a csv has an empty column, that is represented by consecutive commas. The same is true in other similar formats with fixed delimiters. In that case, when you use `.split()` to identify the columns, you want to get back an empty string for any that are missing so that your 4th column is still 4th in your list. If empty strings were removed, then you would have no idea which column is which for lines missing one or more columns.\n",
    "\n",
    "In this way, `.split()` is kind of like two methods in one. It behaves differently depending on how you run it. It is important to be aware of these two modes of operaton when using it as you may need to process the outputs differently in each case.\n",
    "\n",
    "As for the data we have been working with here, as each line only has whitespace between the columns, and has no whitespace within each column (e.g., if you had tab-separated columns, but could have multiple words in a column), we can use `.split()` with its default mode instead of splitting on tabs. That will remove the trailing newline for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7249699-3db3-4c27-bcbc-f4ea4658366b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4.17', '5.58', '5.18', '6.11', '4.5', '4.61', '5.17', '4.53', '5.33', '5.14']\n"
     ]
    }
   ],
   "source": [
    "file = open(\"plantgrowth.txt\")\n",
    "treatment_weights_dict = {}\n",
    "for line in file.readlines()[1:]:\n",
    "    weight, treatment = line.split() # lines look like \"weight\\tgroup\\n\"\n",
    "    if treatment in treatment_weights_dict:\n",
    "        treatment_weights_dict[treatment].append(weight)\n",
    "    else: \n",
    "        treatment_weights_dict[treatment] = [weight]\n",
    "\n",
    "file.close()\n",
    "print(treatment_weights_dict[\"ctrl\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bc2122-31e4-4d28-bf1d-ce7b13859f34",
   "metadata": {},
   "source": [
    "### Chaining methods\n",
    "\n",
    "In the above example (before talking about the details of `.split()`), we used a syntax that we haven't covered yet: `line.strip().split(\"\\t\")`. If you've never seen that kind of syntax before, it might look complicated. However, the way it is working is very simple. When reading code with chained methods like that, you just need to keep in mind two things: the order of operations, and the class being returned by each method.\n",
    "\n",
    "#### Order of operations\n",
    "\n",
    "chains of methods are executed in the same direction you read them: left to right. You can think about what's going on as being the same idea as the process-substitution we used in Bash (i.e., the syntax `$(<command>)`). Let's walk through the order of operations of the line `line.strip().split(\"\\t\")` to illustrate what is happening.\n",
    "\n",
    "The first component of the statement is the variable `line`. `line` will contain different data on each line of our file, but let's consider the first line for this example: \"weight\\tgroup\\n\". What Python does can be thought of as replacing the word \"line\" in that statement with the contents of the `line` variable. We could therefore rewrite the statement as `\"weight\\tgroup\\n\".strip().split(\"\\t\")`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16a1a90a-c395-4985-a91a-d99230b685e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weight', 'group']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"weight\\tgroup\\n\".strip().split(\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d5becc-078c-431b-9e58-fa14d8e2f849",
   "metadata": {},
   "source": [
    "The next thing to execute is the `.strip()` method. `.strip()` removes whitespace characters from either end of a `str`. In this case, it returns the following (we can check by just running that portion of the statement):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d18ad76-e42a-443f-8411-c5a5bd938910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'weight\\tgroup'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"weight\\tgroup\\n\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f094def-e1f3-40e2-a4c5-67d20a02ca8d",
   "metadata": {},
   "source": [
    "The output of `.strip()` is what `.strip()` is then run on. You can think of the statement up to that point as having been replaced by its output. i.e.,:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4eb99e9f-626f-4b45-a257-9b152b93d45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weight', 'group']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'weight\\tgroup'.split(\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090d519a-0443-4f3b-87a4-1064e76c44c5",
   "metadata": {},
   "source": [
    "As you can see, that output is exactly the same as the output of our original statement.\n",
    "\n",
    "#### Return types\n",
    "\n",
    "As we just saw, when you have a chain of methods, they are executed in sequence from left to right. Each method is executed on the output of the previous. In the example we just considered, we started with a `str`, used `.strip()` which returned a new `str` and then used `.split()` which returned a list. But what if we wanted to add another method to the chain? Which methods can we use?\n",
    "\n",
    "Both of the methods used in the example above are `str` methods. We could use `str` methods because at each step in the chain we were working with a `str`. However, once a `list` is returned by `.split()`, if we try to use a `str` method, we will get an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e5364e4-3f6e-4ade-8f36-80179cb5264e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgroup\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtreatment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "\"weight\\tgroup\\n\".strip().split(\"\\t\").replace(\"group\", \"treatment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a11f5e3-8559-493f-88e4-8d715946418d",
   "metadata": {},
   "source": [
    "As the error states, once a method in the chain has returned a `list`, it is no longer possible to use `str` methods, because we are no longer working with a `str`. As `.split()` returns a `list`, we can now only use `list` methods. For example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8f6ad919-73fa-41fa-83e3-be6481cb9e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"weight\\tgroup\\n\".strip().split(\"\\t\").index(\"group\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec699355-adf0-48dc-8186-a430ddce7bbd",
   "metadata": {},
   "source": [
    "You can chain together methods in any case where each method returns an instance of some class or another. If you use a method like `list.append()`, which performs a modification in-place and doesn't return anything, then you can't add another method afterwards.\n",
    "\n",
    "For example, we can get a list of the columns in the first line of a file using a single line by chaining together methods used in the example earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a92eb87-42f0-453c-b344-601eb406cea4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['weight', 'group']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"plantgrowth.txt\").read().split(\"\\n\")[0].split(\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c61988-363b-4e77-bae6-04834524e881",
   "metadata": {
    "tags": []
   },
   "source": [
    "That single line works, but it is much more difficult to read than performing the same operations over multiple lines. You should use short chains of methods whenever you think it is a clearer way to write code to perform a certain operation. If you start writing long chains like the line above, you might want to reconsider if you are writing your code in the clearest way.\n",
    "\n",
    "## Converting data\n",
    "\n",
    "When you read data from a file using `.read()` or `.readlines()`, the file contents are always read as `str`s. In many cases, the data you are reading from the file are actually numbers. In those cases you must convert the data into the appropriate type. When we used `awk` during the Bash portion of this course, numbers in text files were handled automatically. However, Python doesn't work that way. Python doesn't try to guess what you are trying to do. Instead, it requires that you are explicit.\n",
    "\n",
    "The data in the \"plantgrowth.txt\" file we have been working with include numerical weights. As those weights include decimal places, we will need to convert those data to `floats`. If we didn't care about the decimals, we could convert them to `int`s instead, but the numbers would be rounded **down** to the nearest integer.\n",
    "\n",
    "We can modify out file reading approach to convert the data during file reading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0eb98a80-219d-4740-aaee-57cf9095480f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.17, 5.58, 5.18, 6.11, 4.5, 4.61, 5.17, 4.53, 5.33, 5.14]\n"
     ]
    }
   ],
   "source": [
    "file = open(\"plantgrowth.txt\")\n",
    "treatment_weights_dict = {}\n",
    "for line in file.readlines()[1:]:\n",
    "    weight, treatment = line.split() # lines look like \"weight\\tgroup\\n\"\n",
    "    weight = float(weight) # perhaps simplest/clearest way is reassigning to the same variable\n",
    "    if treatment in treatment_weights_dict:\n",
    "        treatment_weights_dict[treatment].append(weight)\n",
    "    else: \n",
    "        treatment_weights_dict[treatment] = [weight]\n",
    "\n",
    "file.close()\n",
    "print(treatment_weights_dict[\"ctrl\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e4c49-7591-47c1-8423-33f4b30dcf00",
   "metadata": {},
   "source": [
    "As you can see, the numbers are no longer printed in quotes. in addition, we can confirm that they are now `float`s using `type()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c08e64b-f2a9-4d42-9f57-b77a8a19ed65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(treatment_weights_dict[\"ctrl\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcad7d7-029d-4282-8457-b831be3bbd41",
   "metadata": {},
   "source": [
    "## `write()`\n",
    "\n",
    "Once we have read the data in a file and performed some sort of operation on it, it is common to want to next write the output of that operation to a file. To do this, we can use the `write()` method of the open file class we have been working with. The syntax looks a lot like the `.read()` method, except that instead of reading the file contents into a single string, we instead write a single string to a file.\n",
    "\n",
    "Let's say, for example, that we wanted to write the mean average weight of plants in each group to an output file. We could do that as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d9e65f2-0107-41e4-97f4-2c9e05ee9300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ctrl': 5.032, 'trt1': 4.661, 'trt2': 5.526}\n"
     ]
    }
   ],
   "source": [
    "# First make a variable to contain the averages. A dict seems like a sensible object for that\n",
    "# We could store these data in something else, but a dict would be useful in case we want to look up a mean later in the script\n",
    "mean_weights_dict = {}\n",
    "\n",
    "# next, we can iterate over the keys and values in our treatment_weights_dict to calculate the mean of each treatment\n",
    "for treatment, weights in treatment_weights_dict.items(): # dict.items() returns each key and value one by one as an iterator\n",
    "    # count the number of measurements for later use\n",
    "    num_weights = len(weights)\n",
    "    # Python has a built-in sum function to add up the weights\n",
    "    sum_weights = sum(weights)\n",
    "    # then we can add the mean to our dict\n",
    "    mean_weights_dict[treatment] = sum_weights/num_weights\n",
    "\n",
    "print(mean_weights_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adeea3e-3195-4b6b-b4c3-cf249a362962",
   "metadata": {},
   "source": [
    "Now we have our data, next we need to organize it into a writeable format (i.e., a `str`). The most straightforward way to do that would be with string concatenation. That would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3afb598-1c8b-4772-b1b9-0176eb64a093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment\tMean_Weight\n",
      "ctrl\t5.032\n",
      "trt1\t4.661\n",
      "trt2\t5.526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First make a str to store our output. We can start it off with a header line\n",
    "out_contents = \"Treatment\\tMean_Weight\\n\"\n",
    "for treatment, mean_weight in mean_weights_dict.items():\n",
    "    out_contents += treatment + \"\\t\" + str(mean_weight) + \"\\n\"\n",
    "\n",
    "print(out_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0253f94d-d9e0-429e-9f4e-bb3bac9b6ef9",
   "metadata": {},
   "source": [
    "That output looks like exactly how our file should look. Let's write that file and then we will talk about a couple of best practices when building large `str` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "639d509b-be91-4a5b-8263-182f0d2ffc6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file you want to write to. The file doesn't need to exist. this operation is like \">\" in Bash\n",
    "file = open(\"mean_weights.txt\", 'w') # 'w' mode means we will write to the file\n",
    "file.write(out_contents)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18815044-2e49-4e6d-b1e5-9369f046362a",
   "metadata": {},
   "source": [
    "That's all it takes. There is now a file called mean_weights.txt in your current directory.\n",
    "\n",
    "## f-strings\n",
    "\n",
    "Creating the above `str` to write to our output file was fairly straightforward. However, it was more complicated than it needed to be (at least in terms of code elements written). Since Python version 3.6, Python has supported a better way: f-strings. f-strings are a modified form of the `str` class that supports what we called variable substitution in Bash. Basically, f-strings let you put your variables within a string. Additionally, while we had to convert our `float` `mean_weight` variable into a `str`, f-strings handle the conversion for us. f-strings look like this:\n",
    "\n",
    "`f\"some string stuff {<variable>} more string stuff {<another variable>}\"`\n",
    "\n",
    "In Bash you could specify your variables with \"\\\\$\" and perhaps put curly braces around them if you had other characters following your variable name. Python doesn't use \"\\\\$\" to declare variables, so you always need to put curly braces (\"{}\") around your variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae28704c-ada9-44c7-b0e5-bd8dab5e9eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a is some_string, b is 1, c is 3.14, d is [1, 2, 3], the length of d is 3\n"
     ]
    }
   ],
   "source": [
    "a = \"some_string\" # str\n",
    "b = 1 # int\n",
    "c = 3.14 # float\n",
    "d = [1,2,3] # list\n",
    "\n",
    "result = f\"a is {a}, b is {b}, c is {c}, d is {d}, the length of d is {len(d)}\"\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2466c575-44b9-470b-b8ea-2bc96397e873",
   "metadata": {},
   "source": [
    "f-strings can look a lot cleaner and more readable than having lots of type conversion and concatenation operations. Let's look at how f-strings would look in the code we used to create our output file earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8def4edd-783f-4e42-bc3e-9d52c149dd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment\tMean_Weight\n",
      "ctrl\t5.032\n",
      "trt1\t4.661\n",
      "trt2\t5.526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_contents = \"Treatment\\tMean_Weight\\n\"\n",
    "for treatment, mean_weight in mean_weights_dict.items():\n",
    "    out_contents += f\"{treatment}\\t{mean_weight}\\n\"\n",
    "    \n",
    "print(out_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcce70d0-1c90-43ff-9734-a19b05634607",
   "metadata": {},
   "source": [
    "We get the same output, but the characters written in your code are closer to how your final output will look. You can decide whether you want to use f-strings in your code.\n",
    "\n",
    "## String-building best-practice\n",
    "\n",
    "As we saw in Bash, string concatenation is slow. The same is true in Python. In Python that is because when you add two `str`s together, you are copying all of the data from each `str` to a new location in memory. You aren't just modifying an existing `str` instance. For short strings like what we have been working with here, that isn't an issue. However, if you were to want to write a file with thousands of lines, then you would have much longer run times using string concatenation than if you used a faster method. Specifically, you should instead make a `list` and then join the completed `list` together using `str.join()`. Our current code for creating our output contents would look like this if we use a `list` instead of a `str` to build our output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc991950-9ae9-4ec8-85ce-9ea16fd371d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treatment\tMean_Weight\n",
      "ctrl\t5.032\n",
      "trt1\t4.661\n",
      "trt2\t5.526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out_list = [\"Treatment\\tMean_Weight\\n\"]\n",
    "for treatment, mean_weight in mean_weights_dict.items():\n",
    "    out_list.append(f\"{treatment}\\t{mean_weight}\\n\")\n",
    "\n",
    "out_contents = \"\".join(out_list)\n",
    "print(out_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9e8df0-3803-45a9-a62d-327edc22eae1",
   "metadata": {},
   "source": [
    "As you can see, the output is the same. If you are curious to see the difference in time, you can run the following code, which will make 100,000 lines of `str` concatenation and 100,000 lines of list followed by a `str.join()` operation.\n",
    "\n",
    "Output in my test:\n",
    "\n",
    "string concatenation took 7.171992063522339 seconds\n",
    "list building and joining took 0.004171848297119141 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fe22e4c-ac35-4f2e-8492-2e2d4317cef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string concatenation took 7.171992063522339 seconds\n",
      "list building and joining took 0.004171848297119141 seconds\n"
     ]
    }
   ],
   "source": [
    "import time # We'll cover this syntax below\n",
    "str_start = time.time() # We'll cover this later too\n",
    "string = \"\"\n",
    "# We can use the built-in function range() to loop over a range of numbers\n",
    "for _ in range(100_000): # You can use underscores to break up numbers into readable groups like how commas are used in written numbers\n",
    "    string += \"something\\n\"   \n",
    "print(f\"string concatenation took {time.time()-str_start} seconds\")\n",
    "\n",
    "list_start = time.time()\n",
    "lst = []\n",
    "for _ in range(100_000):\n",
    "    lst.append(\"something\\n\")\n",
    "string = \"\".join(lst)\n",
    "print(f\"list building and joining took {time.time()-list_start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d8235a-f978-40ec-8df8-422bd3871c64",
   "metadata": {},
   "source": [
    "As you can see, the run time of string concatenation was thousands of times slower, even when adding a short string. If we had used longer line lengths, then the run time would have been even longer for string concatenation, while list joining would not be noticeably affected.\n",
    "\n",
    "Output in my test:\n",
    "\n",
    "string concatenation took 19.156351804733276 seconds\n",
    "list building and joining took 0.004466056823730469 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "23a905ac-6097-4c94-bf07-103ea8be3829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "string concatenation took 19.156351804733276 seconds\n",
      "list building and joining took 0.004466056823730469 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "str_start = time.time()\n",
    "string = \"\"\n",
    "for _ in range(100_000):\n",
    "    string += \"something even longer\\n\" \n",
    "print(f\"string concatenation took {time.time()-str_start} seconds\")\n",
    "\n",
    "list_start = time.time()\n",
    "lst = []\n",
    "for _ in range(100_000):\n",
    "    lst.append(\"something even longer\\n\")\n",
    "string = \"\".join(lst)\n",
    "print(f\"list building and joining took {time.time()-list_start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb5139-9b5f-4578-a17e-d95412b9e0a0",
   "metadata": {},
   "source": [
    "## reading command line input\n",
    "\n",
    "It is rarely valuable to hard-code file paths in your scripts. Doing so will make it so that you can only run a script if it and any files are in the correct location. Furthermore, you can't then run your script on other files without editing the script for every file.\n",
    "\n",
    "Python does provides the ability to read information from commandline input. However, you need to import the \"sys\" module to gain access to that functionality.\n",
    "\n",
    "### What is a module?\n",
    "\n",
    "A module is a set of classes and/or functions which provide some sort of functionality. Typically, a module's classes and functions will all be useful for related tasks. For example, the \"sys\" module provides functionality for interacting with and accessing system parameters. The \"time\" module provides functionality for recording the time and date and converting between date and time formats.\n",
    "\n",
    "Python includes several built-in functions that you always have access to in a Python environment. However, there is lots of functionality you might want to have access to when writing Python code. [Python comes with a lot of optional modules called the \"standard library\"](https://docs.python.org/3/library/index.html). You can import any module in the standard library without needing to install anything extra and can assume that anyone else running your script will have the standard library on their system as well.\n",
    "\n",
    "### Why are there modules instead of always having everything loaded?\n",
    "\n",
    "Organizing functionality into modules in the standard library rather than having everything available all the time has a few benefits. \n",
    "\n",
    "First, having more modules loaded increases the time taken for your script to run. If you aren't going to use most of the modules, it makes sense to not slow your execution time needlessly. \n",
    "\n",
    "Second, keeping things organized into modules leaves you with a cleaner namespace. We'll talk more about namespace later, but basically, by organizing functions and classes into modules, you don't have to worry so much about having two functions with the same name. To refer to the `time()` function in the \"time\" module above, we used `time.time()`. If we have another time function in another module we would refer to it as `other_module.time()`. If both functions were loaded directly into our script, it would be difficult to be clear about which time function you wanted to run.\n",
    "\n",
    "### Reading commandline input with the `sys` module\n",
    "\n",
    "To read input provided in the commandline, you can use the `sys` module. Specifically, `sys` stores each input in a list that you can access using `sys.argv` (short for \"argument vector\"). The numbering of elements in the list is the same as we saw in Bash. i.e., the oneth element is your first input, while the zeroth element is your script name. You can access each element by indexing the list. Therefore, the first input given in the commandline is `sys.argv[1]`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
